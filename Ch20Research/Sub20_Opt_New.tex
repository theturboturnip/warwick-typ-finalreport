\subsection{New Optimizations}
\label{sec:FutureOptimization}
CPUs and GPUs have very distinct designs, so when moving programs between them it's important to acknowledge optimization techniques that apply to one and not the other.
This section sums up the research into optimizing CUDA programs, which should be applied when designing/implementing the final program.

% CUDA devices are split into many threads, which are split into groups of 32 that are executed concurrently as a warp\cite{tool:CUDAProgrammingV1}.
CUDA devices combine groups of 32 threads into a `warp', and executes them concurrently\cite{tool:CUDAProgrammingV1}.
If the threads in a warp attempt to access multiple words in the same cache line, the access is \textit{coalesced}\cite{NVIDIAHowBlog} and only one cache line needs to be fetched for the warp to continue.
Otherwise if the accesses all touch different cache lines, every cache line needs to be fetched before execution can continue for any of the threads.
This should be accounted for when structuring GPU work.

% Const Restrict Pointers for __ldg (https://dl.acm.org/doi/pdf/10.1145/3238147.3241533 tries to do this automatically and found a perf boost, can cite that or cite other papers on it).
% \todomark{This seems more like a statement of an optimization than a "Future Work".}
The CUDA C Programming Guide\cite{NVIDIAGlobalGuide} states that read-only memory can be read into a special data cache using the \texttt{\_\_ldg()} intrinsic.
The compiler may insert this automatically when it detects that data must be read-only.
The use of \texttt{const} and \texttt{\_\_restrict\_\_} qualifiers on pointers that are read-only is encouraged to make read-only data obvious.
In \cite{10.1145/3238147.3241533} it was found that introducing these qualifiers where possible led to large speedups in pointer heavy applications, and while our case may not use many pointers this should still be implemented wherever possible.

% GPU Vectorization (cite).
The ACA solution used Intel AVX and SSE instructions\cite{IntelCorporationIntroductionExtensions} to calculate four Poisson values at once\footnote{Vectors of eight were tried but were found to be slower than four.}.
In the Progress Report\todocite{progress report} it was asserted that CUDA cores could use SIMD on four-element floating-point vectors, and that this could be exploited similarly.
However, this is not the case.
The only SIMD instructions CUDA allows are for integer vectors of 2x16-bit or 4x8-bit\cite{NvidiaCUDASIMD}.%\todocite{\url{https://docs.nvidia.com/cuda/parallel-thread-execution/index.html\#data-movement-and-conversion-instructions-ld}}.
As the simulation operates on 32-bit signed floating point, these instructions are not suitable.

% Mention parallelization with OpenMP
% did already?

% Highly optimized reductions (cite).
Calculating the simulation timestep and calculating the residual for a Poisson iteration both require a reduction over large blocks of data.
Highly parallel GPU optimizations have already been studied extensively, so it is trivial to implement a fast generic reduction kernel.
In \cite{CUDAParallelReduction} seven kernels are described, in ascending order of speed, and this should be used as the basis for the implementation.

CUDA Graphs \cite{GrayCUDAGraph2019Blog} are a CUDA feature that reduces CPU overhead by invoking a large amount of GPU work all at once, rather than with individual invocations.
Running a CUDA graph will always use the same arguments as when initially recorded, so any work that depends on data that changes quickly (such as a timestep) would not be suitable.
Profiling should be used to determine when CUDA graphs are suitable, then applied only in these cases to avoid overcomplicating the program.